{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2790d43048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.14037745  1.2763927 ]\n",
      "-9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng=np.random.RandomState(123)\n",
    "d=2\n",
    "N=10\n",
    "mean=5\n",
    "x1=rng.randn(N,d)+np.array([0,0])\n",
    "x2=rng.randn(N,d)+np.array([mean,mean])\n",
    "\n",
    "x=np.concatenate((x1,x2),axis=0)\n",
    "\n",
    "line = plt.figure()\n",
    "\n",
    "plt.scatter (x[:,0], x[:,1])\n",
    "plt.show()\n",
    "\n",
    "# definition of perceptoron\n",
    "w=np.zeros(d)\n",
    "b=0\n",
    "\n",
    "def y(x):\n",
    "    return step(np.dot(w,x)+b)\n",
    "def step(x):\n",
    "    return 1*(x>0)\n",
    "def t(i):\n",
    "    if i<N:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    \n",
    "while True:\n",
    "    classified = True\n",
    "    for i in range(N*2):\n",
    "        delta_w=(t(i)-y(x[i]))*x[i]\n",
    "        delta_b=(t(i)-y(x[i]))\n",
    "        w += delta_w\n",
    "        b += delta_b\n",
    "        classified *= all(delta_w==0)*(delta_b==0)\n",
    "    if classified:\n",
    "        break\n",
    "        \n",
    "print(w)\n",
    "print(b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "[[ 0.22355038]\n",
      " [ 0.91425949]\n",
      " [ 0.91425949]\n",
      " [ 0.99747425]]\n",
      "w:  [[ 3.61188436]\n",
      " [ 3.61188436]]\n",
      "b:  [-1.24509501]\n"
     ]
    }
   ],
   "source": [
    "# perceptron with tensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "w= tf.Variable(tf.zeros([2,1]))\n",
    "b= tf.Variable(tf.zeros([1]))\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "t=tf.placeholder(tf.float32,shape=[None,1])\n",
    "y=tf.nn.sigmoid(tf.matmul(x,w)+b)\n",
    "\n",
    "cross_entropy=-tf.reduce_sum(t*tf.log(y)+(1-t)*tf.log(1-y))\n",
    "train_step=tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction=tf.equal(tf.to_float(tf.greater(y,0.5)),t)\n",
    "\n",
    "# OR gate\n",
    "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y=np.array([[0],[1],[1],[1]])\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# training\n",
    "for epoch in range(200):\n",
    "    sess.run(train_step,feed_dict={\n",
    "        x:X,\n",
    "        t:Y\n",
    "    })\n",
    "    \n",
    "#display results\n",
    "\n",
    "classified=correct_prediction.eval(session=sess, feed_dict={\n",
    "    x:X,\n",
    "    t:Y\n",
    "})\n",
    "print (classified)\n",
    "\n",
    "prob=y.eval(session=sess, feed_dict={\n",
    "    x:X,\n",
    "    t:Y  \n",
    "})\n",
    "print (prob)\n",
    "\n",
    "print ('w: ', sess.run(w))\n",
    "print('b: ', sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s - loss: 0.5649     \n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s - loss: 0.5287     \n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s - loss: 0.5008     \n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s - loss: 0.4784     \n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s - loss: 0.4605     \n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s - loss: 0.4454     \n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s - loss: 0.4326     \n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s - loss: 0.4217     \n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s - loss: 0.4120     \n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s - loss: 0.4034     \n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s - loss: 0.3958     \n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s - loss: 0.3890     \n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s - loss: 0.3827     \n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s - loss: 0.3768     \n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s - loss: 0.3711     \n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s - loss: 0.3658     \n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s - loss: 0.3608     \n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s - loss: 0.3561     \n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s - loss: 0.3516     \n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s - loss: 0.3472     \n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s - loss: 0.3430     \n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s - loss: 0.3389     \n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s - loss: 0.3350     \n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s - loss: 0.3311     \n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s - loss: 0.3275     \n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s - loss: 0.3238     \n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s - loss: 0.3203     \n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s - loss: 0.3168     \n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s - loss: 0.3135     \n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s - loss: 0.3102     \n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s - loss: 0.3069     \n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s - loss: 0.3037     \n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s - loss: 0.3006     \n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s - loss: 0.2976     \n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s - loss: 0.2947     \n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s - loss: 0.2917     \n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s - loss: 0.2889     \n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s - loss: 0.2860     \n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s - loss: 0.2833     \n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s - loss: 0.2806     \n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s - loss: 0.2779     \n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s - loss: 0.2753     \n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s - loss: 0.2727     \n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s - loss: 0.2702     \n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s - loss: 0.2677     \n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s - loss: 0.2653     \n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s - loss: 0.2629     \n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s - loss: 0.2605     \n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s - loss: 0.2582     \n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s - loss: 0.2559     \n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s - loss: 0.2536     \n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s - loss: 0.2514     \n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s - loss: 0.2493     \n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s - loss: 0.2471     \n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s - loss: 0.2450     \n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s - loss: 0.2429     \n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s - loss: 0.2409     \n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s - loss: 0.2389     \n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s - loss: 0.2369     \n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s - loss: 0.2350     \n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s - loss: 0.2331     \n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s - loss: 0.2311     \n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s - loss: 0.2293     \n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s - loss: 0.2275     \n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s - loss: 0.2257     \n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s - loss: 0.2239     \n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s - loss: 0.2221     \n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s - loss: 0.2204     \n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s - loss: 0.2187     \n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s - loss: 0.2170     \n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s - loss: 0.2153     \n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s - loss: 0.2137     \n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s - loss: 0.2121     \n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s - loss: 0.2105     \n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s - loss: 0.2090     \n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s - loss: 0.2074     \n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s - loss: 0.2059     \n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s - loss: 0.2044     \n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s - loss: 0.2029     \n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s - loss: 0.2014     \n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s - loss: 0.2000     \n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s - loss: 0.1986     \n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s - loss: 0.1972     \n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s - loss: 0.1958     \n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s - loss: 0.1944     \n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s - loss: 0.1931     \n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s - loss: 0.1917     \n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s - loss: 0.1904     \n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s - loss: 0.1891     \n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s - loss: 0.1878     \n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s - loss: 0.1866     \n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s - loss: 0.1853     \n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s - loss: 0.1841     \n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s - loss: 0.1829     \n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s - loss: 0.1817     \n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s - loss: 0.1805     \n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s - loss: 0.1793     \n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s - loss: 0.1781     \n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s - loss: 0.1770     \n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s - loss: 0.1759     \n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s - loss: 0.1748     \n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s - loss: 0.1736     \n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s - loss: 0.1726     \n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s - loss: 0.1715     \n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s - loss: 0.1704     \n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s - loss: 0.1694     \n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s - loss: 0.1683     \n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s - loss: 0.1673     \n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s - loss: 0.1663     \n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s - loss: 0.1653     \n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s - loss: 0.1643     \n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s - loss: 0.1633     \n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s - loss: 0.1623     \n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s - loss: 0.1614     \n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s - loss: 0.1604     \n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s - loss: 0.1595     \n",
      "Epoch 117/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.007 - 0s - loss: 0.1585     \n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s - loss: 0.1576     \n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s - loss: 0.1567     \n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s - loss: 0.1558     \n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s - loss: 0.1549     \n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s - loss: 0.1540     \n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s - loss: 0.1531     \n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s - loss: 0.1523     \n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s - loss: 0.1514     \n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s - loss: 0.1506     \n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s - loss: 0.1497     \n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s - loss: 0.1489     \n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s - loss: 0.1481     \n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s - loss: 0.1473     \n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s - loss: 0.1465     \n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s - loss: 0.1457     \n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s - loss: 0.1449     \n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s - loss: 0.1441     \n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s - loss: 0.1434     \n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s - loss: 0.1426     \n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s - loss: 0.1418     \n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s - loss: 0.1411     \n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s - loss: 0.1404     \n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s - loss: 0.1396     \n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s - loss: 0.1389     \n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s - loss: 0.1382     \n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s - loss: 0.1375     \n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s - loss: 0.1368     \n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s - loss: 0.1361     \n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s - loss: 0.1354     \n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s - loss: 0.1347     \n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s - loss: 0.1340     \n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s - loss: 0.1333     \n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s - loss: 0.1327     \n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s - loss: 0.1320     \n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s - loss: 0.1314     \n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s - loss: 0.1307     \n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s - loss: 0.1301     \n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s - loss: 0.1294     \n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s - loss: 0.1288     \n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s - loss: 0.1282     \n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s - loss: 0.1276     \n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s - loss: 0.1269     \n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s - loss: 0.1263     \n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s - loss: 0.1257     \n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s - loss: 0.1251     \n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s - loss: 0.1245     \n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s - loss: 0.1240     \n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s - loss: 0.1234     \n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s - loss: 0.1228     \n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s - loss: 0.1222     \n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s - loss: 0.1217     \n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s - loss: 0.1211     \n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s - loss: 0.1206     \n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s - loss: 0.1200     \n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s - loss: 0.1195     \n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s - loss: 0.1189     \n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s - loss: 0.1184     \n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s - loss: 0.1178     \n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s - loss: 0.1173     \n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s - loss: 0.1168     \n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s - loss: 0.1163     \n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s - loss: 0.1158     \n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s - loss: 0.1153     \n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s - loss: 0.1147     \n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s - loss: 0.1142     \n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s - loss: 0.1137     \n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s - loss: 0.1132     \n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s - loss: 0.1128     \n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s - loss: 0.1123     \n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s - loss: 0.1118     \n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s - loss: 0.1113     \n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s - loss: 0.1108     \n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s - loss: 0.1104     \n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s - loss: 0.1099     \n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s - loss: 0.1094     \n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s - loss: 0.1090     \n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s - loss: 0.1085     \n",
      "Epoch 195/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.083 - 0s - loss: 0.1081     \n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s - loss: 0.1076     \n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s - loss: 0.1072     \n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s - loss: 0.1067     \n",
      "Epoch 199/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.091 - 0s - loss: 0.1063     \n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s - loss: 0.1059     \n",
      "1/4 [======>.......................] - ETA: 0s\n",
      "classified: \n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "output probability: \n",
      "[[ 0.21599583]\n",
      " [ 0.92126906]\n",
      " [ 0.91278803]\n",
      " [ 0.99775559]]\n"
     ]
    }
   ],
   "source": [
    "# OR gate with Keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model=Sequential([\n",
    "    Dense(input_dim=2, units=1),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))\n",
    "\n",
    "# OR gate\n",
    "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y=np.array([[0],[1],[1],[1]])\n",
    "\n",
    "model.fit(X,Y, epochs=200, batch_size=1)\n",
    "\n",
    "classes= model.predict_classes (X, batch_size=1)\n",
    "prob=model.predict_proba(X, batch_size=1)\n",
    "\n",
    "print()\n",
    "print('classified: ')\n",
    "print(Y == classes)\n",
    "print()\n",
    "print('output probability: ')\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
